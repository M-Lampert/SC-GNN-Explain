{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain the GNN predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparations\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.models import GraphSAGE\n",
    "\n",
    "# Snippets from my Master Thesis repository so that the non-relevant parts of the code are as short as possible\n",
    "from src.data_loading import get_spatial_data\n",
    "from src.graph_construction import build_delaunay_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Random Number Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27076b57670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = torch.Generator()\n",
    "rng.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph Construction and Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters\n",
    "\n",
    "The hyperparameters are all chosen according to the results of the evaluation that is the main part of the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For graph construction (Radius Delanay)\n",
    "graph_construction_radius = 0.00018225\n",
    "self_loops = False  # Self-Loops will not be used since we want to minimize the effect of the gene expression profile of the node itself\n",
    "edge_weights = False\n",
    "train_frac = 0.8  # The fraction of nodes that should be used for training. It will be assigned randomly and the rest will be used for testing.\n",
    "\n",
    "# For the GNN model (GraphSAGE)\n",
    "num_layers = 3\n",
    "hidden_channels = 128\n",
    "activation = \"relu\"\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# For the training algorithm (Adam)\n",
    "lr = 0.01\n",
    "weight_decay = 1e-5\n",
    "n_epochs = 144"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell coordinates:  (7416, 2)\n",
      "Features:  (7416, 241)\n",
      "True labels:  (7416,)\n"
     ]
    }
   ],
   "source": [
    "cells, genes = get_spatial_data(\"intestine\")\n",
    "\n",
    "cell_coordinates = cells[[\"x\", \"y\"]].values\n",
    "features = genes.values\n",
    "true_labels = cells[\"cluster_id\"].values\n",
    "ordered_names = (\n",
    "    cells[[\"cluster_id\", \"cell_type\"]].drop_duplicates().set_index(\"cluster_id\").sort_index()[\"cell_type\"].values\n",
    ")\n",
    "\n",
    "print(\"Cell coordinates: \", cell_coordinates.shape)\n",
    "print(\"Features: \", features.shape)\n",
    "print(\"True labels: \", true_labels.shape)  # Must be 1D array!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Radius-Delaunay Graph\n",
    "\n",
    "This is the overall best performing graph construction method so we will use it for the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 19\n",
      "Number of nodes: 7416\n",
      "Number of edges: 44452\n",
      "Average degree: 5.994066882416397\n"
     ]
    }
   ],
   "source": [
    "graph = build_delaunay_graph(\n",
    "    positions=cell_coordinates,\n",
    "    include_self_loops=self_loops,\n",
    "    add_distance=edge_weights,\n",
    "    features=features,\n",
    "    labels=true_labels, # TODO: Change to `features` since this is our new target\n",
    "    library=\"pyg\", # The only available option since the code snippet is not the complete version of the normal code\n",
    ")\n",
    "\n",
    "num_labels = len(np.unique(true_labels))\n",
    "num_nodes = graph.num_nodes\n",
    "num_edges = graph.num_edges\n",
    "\n",
    "print(\"Number of labels:\", num_labels)\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)\n",
    "print(\"Average degree:\", num_edges / num_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "Since we are not changing any hyperparameter and are not really interested in the performance of the model itself, we will omit the validation set and just use the test set for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_random_splits(graph: Data) -> Data:\n",
    "    \"\"\"Takes the generated PyG graph as input and assigns a mask for the train and test split that is used for training and evaluation. The PyG graph will be returned with the assigned split.\"\"\"\n",
    "    graph = graph.clone()\n",
    "    random_indices = torch.randperm(num_nodes, generator=rng)\n",
    "\n",
    "    train_indices = random_indices[: int(num_nodes * train_frac)]\n",
    "    test_indices = random_indices[int(num_nodes * train_frac) :]\n",
    "\n",
    "    # Not all datatypes are allowed for the index: Only bool, byte or long\n",
    "    graph.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    graph.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    graph.train_mask[train_indices] = 1\n",
    "    graph.test_mask[test_indices] = 1\n",
    "    return graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think the easiest way to implement this is to wrap the initialised GNN model we want to use\n",
    "# This should then only be used in combination with gradient descent versions that do not use any batches but work on every node individually\n",
    "\n",
    "class MaskedGNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model: torch.nn.Module, masking_type: str = \"ones\"):\n",
    "        \"\"\"Initializes the masker model\n",
    "\n",
    "        Args:\n",
    "            model: Any GNN model\n",
    "            masking_type: Either \"ones\" or \"avg\" which could be the cell type average as discussed. Defaults to \"ones\".\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.masking_type = masking_type\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"Forward function that masks the node that is used for prediction\n",
    "\n",
    "        Args:\n",
    "            x: The input node features.\n",
    "            edge_index: The edge indices (the graph or more specifically the adjacency list representation that is used by PyG)\n",
    "\n",
    "        Returns:\n",
    "            The predictions\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Find the index of the node that should be predicted and mask it\n",
    "        \n",
    "        return self.model(x, edge_index) # Do the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The configurations chosen in the following are chosen as the overall best after the main grid search\n",
    "def train_model(graph: Data) -> tuple[GraphSAGE, Data]:\n",
    "    \"\"\"Initializes and trains the model\"\"\"\n",
    "    model=GraphSAGE(\n",
    "        in_channels=features.shape[1],\n",
    "        out_channels=num_labels, # TODO: Change to input size as we want to essentially predict the input\n",
    "        hidden_channels=hidden_channels,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout_rate,\n",
    "        act=activation,\n",
    "        jk=\"last\",  # This adds a final linear layer after the GNN layers\n",
    "        # arguments that are passed to the Convolutional layer\n",
    "        aggr=\"max\",\n",
    "        normalize=True,\n",
    "        root_weight=True,\n",
    "        project=True,\n",
    "        bias=True,\n",
    "    )\n",
    "\n",
    "    # Move model to the correct device memory. Needed for training on the GPU.\n",
    "    model = model.to(device)\n",
    "\n",
    "    graph = assign_random_splits(graph)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    for _ in range(1, n_epochs):\n",
    "        \n",
    "        # TODO: Change from full batch to single batch\n",
    "        # Can be done with the NeighborLoader in PyG: https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader\n",
    "        # An Example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py\n",
    "\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph.x, graph.edge_index)\n",
    "        loss = F.cross_entropy(out[graph.train_mask], graph.y[graph.train_mask]) # TODO: Change to something that is fitting for a regression task. MSE probably...\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the model\n",
    "    pred = model(graph.x, graph.edge_index).argmax(dim=-1)\n",
    "    acc = int((pred[graph.test_mask] == graph.y[graph.test_mask]).sum()) / int(graph.test_mask.sum())\n",
    "    print(f\"Finished training with an accuracy of {acc:.4f} for the test set\")\n",
    "\n",
    "    return model, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with an accuracy of 0.8794 for the test set\n"
     ]
    }
   ],
   "source": [
    "graph = graph.to(device)\n",
    "model, curr_graph = train_model(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
